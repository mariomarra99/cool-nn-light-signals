<h1 id="h1-traffic-light-detection-classification"><a name="Traffic-light-detection-classification" class="reference-link"></a><span class="header-link octicon octicon-link"></span>Traffic-light-detection-classification</h1><p>Progetto sulla ricerca di metodi per una efficace <strong>detection</strong> e <strong>classification</strong> di semafori.<br>Parte fondante e fondamentale sia per il progetto che per la presentazione si può trovare qui:<br><a href="https://colab.research.google.com/drive/16xmd3PJsmGA4x6rRYSjiZmGbOVb2SRzn?authuser=3#scrollTo=lOjlW3JWwDrB">https://colab.research.google.com/drive/16xmd3PJsmGA4x6rRYSjiZmGbOVb2SRzn?authuser=3#scrollTo=lOjlW3JWwDrB</a></p>
<p>In particolare ci sono quasi tutte le sperimentazioni che ho effettuato sia in ambito <strong>AI</strong> sia in ambito <strong>Computer Vision</strong>. Ho cercato di utilizzare tutti e due gli approcci, soprattutto per lavorare sul semaforo dopo la detection. </p>
<h2 id="h2-introduzione"><a name="Introduzione" class="reference-link"></a><span class="header-link octicon octicon-link"></span>Introduzione</h2><p>A fronte di idee propostemi da <a href="mailto:kaszuba@diag.uniroma1.it">kaszuba@diag.uniroma1.it</a> , sono arrivato a questa idea qui. Inizialmente il task doveva occupare un campo molto più ampio, ma sicuramente l’esperienza acquisita per risolvere questo ‘problema’ può risultare utile anche per spaziare eventualmente in futuro. </p>
<p>L’utilizzo di segnali luminosi è molto diffuso in diversi ambiti, non solo per le strade ma anche in ambito industriale e agricolo come “controllori” del corretto funzionamento delle macchine.  Ad oggi, per verificare che funzionano, si utilizzano tendenzialmente cavi collegati direttamente al terminale che li gestisce. Tuttavia, soprattutto in grosse industrie, ci sono tanti device da controllare per cui, oltre ai costi, sorge un problema: chi controlla i controllori? Di solito vengono assunti degli addetti umani, ma perché farlo se possiamo risparmiare utilizzando un pc di fascia media e una telecamera neanche troppo dispendiosa? </p>
<p>L’obiettivo di questo progetto è quindi di scandagliare tra le varie metodologie e trovare quelle più efficaci all’impronta dell’ergonomia. </p>
<p>Purtroppo uno dei limiti era la mancanza di <strong>dataset</strong> specifici, per cui di fatto abbiamo certezze solo sui semafori.  In ogni caso la struttura di un segnale luminoso è sempre più o meno quella : tendenzialmente a colonna verticale od orizzontale, lente illuminata se si verifica una condizione, sennò spenta. </p>
<h2 id="h2-dataset"><a name="Dataset" class="reference-link"></a><span class="header-link octicon octicon-link"></span>Dataset</h2><p><strong>S2TLD</strong>:  5786 immagini di circa 1,080 x 1,920 pixels e 720 x 1,280 pixels. Contiene 5 categorie (Verde, Giallo, Rosso, wait on e off) di 14130 instances.  Lo utilizzeremo sia per la verifica della <strong>detection</strong> che per quella della classification. <a href="https://github.com/Thinklab-SJTU/S2TLD"> Link.</a></p>
<p><strong>jeremyscatigna/Traffic_light_classifier/traffic_light_images</strong>: derivativo del <strong>MIT self-driving car course</strong> , 1484 immagini che verranno portati a 32x32 pixel in fase di <strong>precompiling</strong>. Contiene tre categorie (Verde, Giallo, Rosso). Lo utilizzeremo per validare la <strong>classificazione</strong> e per il <strong>training</strong> di un algoritmo. <a href="https://github.com/jeremyscatigna/Traffic_light_classifier">Link.</a></p>
<h2 id="h2-precompiling"><a name="Precompiling" class="reference-link"></a><span class="header-link octicon octicon-link"></span>Precompiling</h2><p><strong>S2TLD</strong>  è strutturato in <strong>Annotations</strong> in xml,  cartella contente le immagini e un file che contiene le class. Per rendere più facile la lettura delle annotations, le ho convertite in file .txt utilizzando la funzione <strong>annotation_xml_read(<em>filename</em>)</strong>  che utilizza il lettore xml di pandas.</p>
<p>Occorrono un paio di <strong>Annotations</strong> che fanno riferimento a immagini senza semafori, quindi a volte dà errore. Ho provveduto a creare “a mano” i corrispondente file .txt.</p>
<p>Per il <strong>dataset</strong> contenuto nella repository di <strong>jeremyscatigna</strong> invece procedo con l’approccio suggerito da <a href="https://github.com/jeremyscatigna/Traffic_light_classifier">lui stesso</a> nella <strong>Sezione 2</strong> per la prima soluzione di <strong>classification</strong> che andrò a presentare. Tuttavia per il <strong>training</strong> semplicemente porto le immagini a 32x32. </p>
<h2 id="h2-detection"><a name="Detection" class="reference-link"></a><span class="header-link octicon octicon-link"></span>Detection</h2></div>
